{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SERC-t-TimeBank.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1WspM2qIf6Wwnc02FF1F7kAjwGVcLh8l4","authorship_tag":"ABX9TyMSYIiui1QRbW+V9N/ibPmG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"OftKjCb0I_ax"},"source":["import pickle\n","import numpy as np\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import *\n","from keras import Model\n","from sklearn.model_selection import train_test_split\n","from keras.callbacks import EarlyStopping\n","import keras.metrics\n","import tensorflow as tf\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import classification_report\n","from torchtext import data\n","import pandas as pd\n","from sklearn.metrics import accuracy_score\n","from torch.utils.data import Dataset, DataLoader\n","from collections import Counter\n","from sklearn.utils import class_weight\n","from sklearn.metrics import precision_recall_fscore_support"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D0RKdcDwM89p"},"source":["def read_data(filename):\n","  dfile = open(filename, 'rb')     \n","  data = pickle.load(dfile)\n","  dfile.close()\n","  return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0v3pGXqx9-v"},"source":["X_train, Y_train, labels_train = read_data('TimeBank/data_train_tb')\n","X_val, Y_val, labels_val = read_data('TimeBank/data_val_tb')\n","X_test, Y_test, labels_test = read_data('TimeBank/data_test_tb')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWFk4gRty0JE"},"source":["unique_tokens = read_data('TimeBank/unique_tokens_tb')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_f9wBcQ6K4ga"},"source":["MAX_NB_WORDS = 5000\n","MAX_SEQUENCE_LENGTH = 140\n","EMBEDDING_DIM = 300\n","\n","TEST_SIZE = 0.15\n","VAL_SIZE = 0.15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nf8b21JI9rHm"},"source":["unique_pos, unique_deps, unique_words = unique_tokens[0], unique_tokens[1], unique_tokens[2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-4y5t8H9YFwp"},"source":["tokenizer1 = Tokenizer(num_words=MAX_NB_WORDS)\n","tokenizer1.fit_on_texts(unique_pos)\n","word_index1 = tokenizer1.word_index\n","\n","tokenizer2 = Tokenizer(num_words=MAX_NB_WORDS)\n","tokenizer2.fit_on_texts(unique_words)\n","word_index2 = tokenizer2.word_index\n","\n","tokenizer3 = Tokenizer(num_words=MAX_NB_WORDS)\n","tokenizer3.fit_on_texts(unique_deps)\n","word_index3 = tokenizer3.word_index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1VI4lkZegeaG"},"source":["#train\n","seq1 = tokenizer1.texts_to_sequences(X_train[0])\n","seq11 = pad_sequences(seq1, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","seq2 = tokenizer2.texts_to_sequences(X_train[2])\n","seq12 = pad_sequences(seq2, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","seq3 = tokenizer3.texts_to_sequences(X_train[1])\n","seq13 = pad_sequences(seq3, maxlen=MAX_SEQUENCE_LENGTH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0pLZ9IJvmydR"},"source":["#val\n","\n","seq1 = tokenizer1.texts_to_sequences(X_val[0])\n","seq11_val = pad_sequences(seq1, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","seq2 = tokenizer2.texts_to_sequences(X_val[2])\n","seq12_val = pad_sequences(seq2, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","seq3 = tokenizer3.texts_to_sequences(X_val[1])\n","seq13_val = pad_sequences(seq3, maxlen=MAX_SEQUENCE_LENGTH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_KjXSkGEgeaG"},"source":["#test\n","\n","seq1 = tokenizer1.texts_to_sequences(X_test[0])\n","seq11_test = pad_sequences(seq1, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","seq2 = tokenizer2.texts_to_sequences(X_test[2])\n","seq12_test = pad_sequences(seq2, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","seq3 = tokenizer3.texts_to_sequences(X_test[1])\n","seq13_test = pad_sequences(seq3, maxlen=MAX_SEQUENCE_LENGTH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PocyTpOdDd_H"},"source":["pos_vec = read_data('pos.vector')\n","dep_vec = read_data('deps.vector')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TwuH756retvz"},"source":["word_vec = {}\n","word_vec['PADDING'] = 300\n","f = open('glove.42B.300d.txt')\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    word_vec[word.lower()] = line\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"si3ARA0yePC1"},"source":["# pos tags\n","\n","embedding_matrix1 = np.zeros((len(word_index1) + 1, 28))\n","for word, i in word_index1.items():\n","    embedding_vector = pos_vec.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix1[i] = np.asarray(embedding_vector.split()[1:], dtype='float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tThSjOoSkI_6"},"source":["#word vec\n","\n","embedding_matrix2 = np.zeros((len(word_index2) + 1, EMBEDDING_DIM))\n","for word, i in word_index2.items():\n","    embedding_vector = word_vec.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix2[i] = np.asarray(embedding_vector.split()[1:], dtype='float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iuj_DKsYekHV"},"source":["# deps vec\n","\n","embedding_matrix3 = np.zeros((len(word_index3) + 1, len(dep_vec['PADDING'])))\n","for word, i in word_index3.items():\n","    embedding_vector = dep_vec.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix3[i] = np.asarray(embedding_vector, dtype='float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAY8pb1vZngy"},"source":["del word_vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3zXkgojnbTd"},"source":["def get_class_weights(training_labels):\n","    class_weights = class_weight.compute_class_weight('balanced',np.unique(training_labels),training_labels)\n","    uni = list(np.unique(training_labels))\n","\n","    labelset = [ 'BEFORE', 'AFTER', 'SIMULTANEOUS', 'IBEFORE', 'IAFTER', 'IS_INCLUDED', 'INCLUDES', 'IDENTITY', 'BEGUN_BY', 'ENDED_BY',\n","    'BEGINS','ENDS','DURING','DURING_INV']\n","\n","    weights = []\n","\n","    for i in labelset:\n","      try:\n","        idx = uni.index(i)\n","        weights.append(class_weights[idx])\n","      except:\n","        weights.append(0)\n","    return weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hOTSKM-As78J"},"source":["\n","\n","# Model"]},{"cell_type":"code","metadata":{"id":"rTjDbczugeaM"},"source":["def defineModel(l1,l2,l3,l4,d1,out,d):\n","\n","    embedding_layer1 = Embedding(len(word_index2) + 1,EMBEDDING_DIM,weights=[embedding_matrix2],input_length=MAX_SEQUENCE_LENGTH,trainable=False)\n","    embedding_layer2 = Embedding(len(word_index1) + 1,28,weights=[embedding_matrix1],input_length=MAX_SEQUENCE_LENGTH,trainable=False)\n","    embedding_layer3 = Embedding(len(word_index3) + 1,77,weights=[embedding_matrix3],input_length=MAX_SEQUENCE_LENGTH,trainable=False)\n","\n","    wi = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32',name=\"inp1\")\n","    wi2 = embedding_layer1(wi)\n","\n","    pi_sen = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32',name=\"inp22\")\n","    pi2_sen = embedding_layer2(pi_sen)\n","\n","    di_sen = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32',name=\"inp33\")\n","    di2_sen = embedding_layer3(di_sen)\n","\n","    lstm1_sen = Bidirectional(LSTM(l1, activation='tanh', dropout=d, return_sequences=True), name = 'bid1temp_sen')(pi2_sen)  #  pos  features\n","    lstm2_sen = Bidirectional(LSTM(l2, activation='tanh', dropout=d, return_sequences=True), name= 'bid2temp_sen')(di2_sen)   #  dep features\n","    lstm3 = Bidirectional(LSTM(l4, activation='tanh', dropout=d+0.1, return_sequences=True), name = 'bid3')(wi2)  #  word features\n","\n","    hid_sen = concatenate([lstm1_sen, lstm2_sen, lstm3])    \n","    \n","    lstm5 = Bidirectional(LSTM(l4, activation='tanh', dropout=d), name = 'bid3templstm2_sen')(hid_sen)\n","\n","    yii = Dense(d1, activation='relu', name='dense1')(lstm5)\n","    yi = Dense(out, activation=\"softmax\", name='dense2')(yii)\n","    model = Model(inputs=[pi_sen,di_sen,wi],outputs=yi)\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p--9j0U7539o"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"3-gpmQwwC01T"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","macro_avg = list()\n","accuracy = list()\n","class_clink = list()\n","class_clinkr = list()\n","checkpoints = list()\n","nodeslist = list()\n","\n","def trainModel():\n","    num_classes = 14\n","\n","    epochs = 50\n","    batchsize = 64\n","    lr = 0.005\n","    file1 = 'TimeBank/chkpt/'\n","    \n","    out = num_classes\n","\n","    training_data, y_train, training_labels, val_data, y_val, val_labels = [seq11, seq13, seq12] , Y_train, labels_train, [seq11_val, seq13_val, seq12_val], Y_val, labels_val\n","    weights = get_class_weights(training_labels)\n","\n","    set_nodes = [32, 32, 64, 64, 32, 0.30]\n","    l1 = set_nodes[0]\n","    l2 = set_nodes[1]\n","    l3 = set_nodes[2]\n","    l4 = set_nodes[3]\n","    d1 = set_nodes[4]\n","    d = set_nodes[5]\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","    checkpoint_filepath = file1 + f'model'   \n","    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,monitor='val_accuracy',mode='max',save_best_only=True)\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n","\n","    model = defineModel(l1,l2,l3,l4,d1,out,d)\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'], loss_weights=weights)\n","    model.fit(x = training_data, y = y_train, epochs = epochs, batch_size = batchsize,validation_data=(val_data,y_val), callbacks=[callback, model_checkpoint_callback], verbose=0)\n","    model.load_weights(checkpoint_filepath)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iOwBL2Xnr85n"},"source":["model = trainModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bsNXJ5XqDXa4"},"source":["batchsize = 64\n","lr = 0.005\n","epochs = 50\n","\n","training_data, y_train, training_labels, val_data, y_val, val_labels = [seq11, seq13, seq12] , Y_train, labels_train, [seq11_val, seq13_val, seq12_val], Y_val, labels_val\n","weights = get_class_weights(training_labels)\n","\n","file1 = 'TimeBank/chkpt/'\n","checkpoint_filepath = file1 + f'model'\n","optimizer =  tf.keras.optimizers.Adam(learning_rate=lr)\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,monitor='val_accuracy',mode='max',save_best_only=True)\n","callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20)\n","model.fit(x = training_data, y = y_train, epochs = epochs, batch_size = batchsize,validation_data=(val_data,y_val), callbacks=[callback,model_checkpoint_callback],verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i72DhaXgSnBf"},"source":["# Best Model Results"]},{"cell_type":"code","metadata":{"id":"xPWOaKQ9qSYM"},"source":["def format_report(report, scores):\n","  # [ 'BEFORE', 'AFTER', 'SIMULTANEOUS', 'IBEFORE', 'IAFTER', 'IS_INCLUDED', 'INCLUDES', 'IDENTITY', 'BEGUN_BY', 'ENDED_BY',\n","    # 'BEGINS','ENDS','DURING','DURING_INV']\n","\n","\n","  print(f\"              {'{0:>10}'.format('precision')} {'{0:>10}'.format('recall')} {'{0:>10}'.format('f1-score')}\")\n","  print(f\"       Before {'{0:>10}'.format(round(report['0']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['0']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['0']['f1-score']*100.0, 1))}\")\n","  print(f\"        After {'{0:>10}'.format(round(report['1']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['1']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['1']['f1-score']*100.0, 1))}\")\n","  print(f\" Simultaneous {'{0:>10}'.format(round(report['2']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['2']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['2']['f1-score']*100.0, 1))}\")\n","  print(f\"      IBefore {'{0:>10}'.format(round(report['3']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['3']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['3']['f1-score']*100.0, 1))}\")\n","  print(f\"       IAfter {'{0:>10}'.format(round(report['4']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['4']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['4']['f1-score']*100.0, 1))}\")\n","  print(f\"  Is Included {'{0:>10}'.format(round(report['5']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['5']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['5']['f1-score']*100.0, 1))}\")\n","  print(f\"     Includes {'{0:>10}'.format(round(report['6']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['6']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['6']['f1-score']*100.0, 1))}\")\n","  print(f\"     Identity {'{0:>10}'.format(round(report['7']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['7']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['7']['f1-score']*100.0, 1))}\")\n","  print(f\"     Begun by {'{0:>10}'.format(round(report['8']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['8']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['8']['f1-score']*100.0, 1))}\")\n","  print(f\"     Ended by {'{0:>10}'.format(round(report['9']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['9']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['9']['f1-score']*100.0, 1))}\")\n","  print(f\"       Begins {'{0:>10}'.format(round(report['10']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['10']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['10']['f1-score']*100.0, 1))}\")\n","  print(f\"         Ends {'{0:>10}'.format(round(report['11']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['11']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['11']['f1-score']*100.0, 1))}\")\n","  print(f\"       During {'{0:>10}'.format(round(report['12']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['12']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['12']['f1-score']*100.0, 1))}\")\n","  print(f\"   During inv {'{0:>10}'.format(round(report['13']['precision']*100.0, 1))} {'{0:>10}'.format(round(report['13']['recall']*100.0, 1))} {'{0:>10}'.format(round(report['13']['f1-score']*100.0, 1))}\")\n","  print(\"\")\n","  print(f\"    micro avg {'{0:>10}'.format(round(scores[0]*100.0, 1))} {'{0:>10}'.format(round(scores[1]*100.0, 1))} {'{0:>10}'.format(round(scores[2]*100.0, 1))}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9MDoxc1ShXm","executionInfo":{"status":"ok","timestamp":1626613486003,"user_tz":-330,"elapsed":5431,"user":{"displayName":"Sanjana Soni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp-piu-0Zjxo8-Zn1GFpKyM8lmlY-IrpARTr0l=s64","userId":"12156689352855342736"}},"outputId":"2782ef3e-d9d2-480e-d550-056e10a3a845"},"source":["data_test = [seq11_test,seq13_test,seq12_test]\n","model = defineModel(32,32,64,64,32,14,0.3)\n","model.load_weights('TimeBank/model_tb.h5', by_name=True)\n","classes = np.argmax(model.predict(x = data_test), axis=-1)\n","y_test_classes = Y_test.argmax(1)\n","y_pred_classes = classes\n","\n","report = classification_report(y_true=y_test_classes, y_pred=y_pred_classes, zero_division=0, output_dict=True, digits= 3, labels=[0,1,2,3,4,5,6,7,8,9,10,11,12,13])\n","scores = precision_recall_fscore_support(y_true=y_test_classes, y_pred=y_pred_classes, average='micro', labels=[0,1,2,3,4,5,6,7,8,9,10,11,12,13])\n","format_report(report, scores)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["               precision     recall   f1-score\n","       Before       35.5       38.6       37.0\n","        After       51.6       61.1       55.9\n"," Simultaneous       31.2       29.4       30.3\n","      IBefore        0.0        0.0        0.0\n","       IAfter        0.0        0.0        0.0\n","  Is Included       50.0       36.4       42.1\n","     Includes       18.8       21.4       20.0\n","     Identity       34.1       46.7       39.4\n","     Begun by        0.0        0.0        0.0\n","     Ended by      100.0       22.2       36.4\n","       Begins        0.0        0.0        0.0\n","         Ends        0.0        0.0        0.0\n","       During        0.0        0.0        0.0\n","   During inv        0.0        0.0        0.0\n","\n","    micro avg       40.3       40.3       40.3\n"],"name":"stdout"}]}]}